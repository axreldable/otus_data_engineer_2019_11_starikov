{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели на RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
       "import org.apache.spark.ml.Pipeline\n",
       "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataSchema: org.apache.spark.sql.types.StructType = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath: String = ./../data/training.1600000.processed.noemoticon.csv\n",
       "raw_sentiment: org.apache.spark.sql.DataFrame = [label: int, tweet: string]\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "    \n",
    "val dataPath= \"./../data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "val raw_sentiment = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\",\"tweet\")\n",
    "\n",
    "raw_sentiment.groupBy($\"label\").count.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_252a0128cf5d\n",
       "hashingTF: org.apache.spark.ml.feature.HashingTF = hashingTF_c657e80c0127\n",
       "labelIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_3d83aee0f371\n",
       "featureIndexer: org.apache.spark.ml.feature.VectorIndexer = vecIdx_c3aa91637d20\n",
       "rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_fe66e9c8f1c5\n",
       "labelConverter: org.apache.spark.ml.feature.IndexToString = idxToStr_582200aa98f4\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_e4bd24ccb25b\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "// Index labels, adding metadata to the label column.\n",
    "// Fit on whole dataset to include all labels in index.\n",
    "val labelIndexer = new StringIndexer()\n",
    "  .setInputCol(\"label\")\n",
    "  .setOutputCol(\"indexedLabel\")\n",
    "  .fit(raw_sentiment)\n",
    "\n",
    "// Automatically identify categorical features, and index them.\n",
    "// Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "val featureIndexer = new VectorIndexer()\n",
    "  .setInputCol(\"features\")\n",
    "  .setOutputCol(\"indexedFeatures\")\n",
    "  .setMaxCategories(4)\n",
    "\n",
    "// Train a RandomForest model.\n",
    "val rf = new RandomForestClassifier()\n",
    "  .setLabelCol(\"indexedLabel\")\n",
    "  .setFeaturesCol(\"indexedFeatures\")\n",
    "  .setNumTrees(10)\n",
    "\n",
    "// Convert indexed labels back to original labels.\n",
    "val labelConverter = new IndexToString()\n",
    "  .setInputCol(\"prediction\")\n",
    "  .setOutputCol(\"predictedLabel\")\n",
    "  .setLabels(labelIndexer.labels)\n",
    "\n",
    "// Chain indexers and forest in a Pipeline.\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, labelIndexer, featureIndexer, rf, labelConverter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-26 17:39:36 WARN  MemoryStore:66 - Not enough space to cache rdd_414_5 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:39:36 WARN  BlockManager:66 - Persisting block rdd_414_5 to disk instead.\n",
      "2020-01-26 17:39:36 WARN  MemoryStore:66 - Not enough space to cache rdd_414_7 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:39:36 WARN  BlockManager:66 - Persisting block rdd_414_7 to disk instead.\n",
      "2020-01-26 17:39:36 WARN  MemoryStore:66 - Not enough space to cache rdd_414_4 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:39:36 WARN  BlockManager:66 - Persisting block rdd_414_4 to disk instead.\n",
      "2020-01-26 17:39:36 WARN  MemoryStore:66 - Not enough space to cache rdd_414_6 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:39:36 WARN  BlockManager:66 - Persisting block rdd_414_6 to disk instead.\n",
      "2020-01-26 17:39:37 WARN  MemoryStore:66 - Not enough space to cache rdd_414_0 in memory! (computed 71.5 MB so far)\n",
      "2020-01-26 17:39:37 WARN  BlockManager:66 - Persisting block rdd_414_0 to disk instead.\n",
      "2020-01-26 17:39:37 WARN  MemoryStore:66 - Not enough space to cache rdd_414_1 in memory! (computed 71.5 MB so far)\n",
      "2020-01-26 17:39:37 WARN  BlockManager:66 - Persisting block rdd_414_1 to disk instead.\n",
      "2020-01-26 17:39:42 WARN  MemoryStore:66 - Not enough space to cache rdd_414_2 in memory! (computed 160.9 MB so far)\n",
      "2020-01-26 17:39:42 WARN  BlockManager:66 - Persisting block rdd_414_2 to disk instead.\n",
      "2020-01-26 17:39:43 WARN  MemoryStore:66 - Not enough space to cache rdd_414_3 in memory! (computed 160.9 MB so far)\n",
      "2020-01-26 17:39:43 WARN  BlockManager:66 - Persisting block rdd_414_3 to disk instead.\n",
      "2020-01-26 17:40:13 WARN  MemoryStore:66 - Not enough space to cache rdd_414_7 in memory! (computed 362.1 MB so far)\n",
      "2020-01-26 17:40:18 WARN  MemoryStore:66 - Not enough space to cache rdd_414_6 in memory! (computed 71.5 MB so far)\n",
      "2020-01-26 17:40:18 WARN  MemoryStore:66 - Not enough space to cache rdd_414_3 in memory! (computed 13.4 MB so far)\n",
      "2020-01-26 17:40:18 WARN  MemoryStore:66 - Not enough space to cache rdd_414_2 in memory! (computed 8.7 MB so far)\n",
      "2020-01-26 17:40:18 WARN  MemoryStore:66 - Not enough space to cache rdd_414_5 in memory! (computed 107.2 MB so far)\n",
      "2020-01-26 17:40:18 WARN  MemoryStore:66 - Not enough space to cache rdd_414_0 in memory! (computed 13.4 MB so far)\n",
      "2020-01-26 17:40:18 WARN  MemoryStore:66 - Not enough space to cache rdd_414_4 in memory! (computed 160.9 MB so far)\n",
      "2020-01-26 17:40:20 WARN  MemoryStore:66 - Not enough space to cache rdd_414_1 in memory! (computed 362.1 MB so far)\n",
      "2020-01-26 17:40:23 WARN  MemoryStore:66 - Not enough space to cache rdd_414_2 in memory! (computed 30.4 MB so far)\n",
      "2020-01-26 17:40:23 WARN  MemoryStore:66 - Not enough space to cache rdd_414_3 in memory! (computed 30.4 MB so far)\n",
      "2020-01-26 17:40:23 WARN  MemoryStore:66 - Not enough space to cache rdd_414_0 in memory! (computed 30.4 MB so far)\n",
      "2020-01-26 17:40:23 WARN  MemoryStore:66 - Not enough space to cache rdd_414_5 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:23 WARN  MemoryStore:66 - Not enough space to cache rdd_414_4 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:23 WARN  MemoryStore:66 - Not enough space to cache rdd_414_6 in memory! (computed 71.5 MB so far)\n",
      "2020-01-26 17:40:24 WARN  MemoryStore:66 - Not enough space to cache rdd_414_7 in memory! (computed 71.5 MB so far)\n",
      "2020-01-26 17:40:25 WARN  MemoryStore:66 - Not enough space to cache rdd_414_1 in memory! (computed 362.1 MB so far)\n",
      "2020-01-26 17:40:29 WARN  MemoryStore:66 - Not enough space to cache rdd_414_7 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:29 WARN  MemoryStore:66 - Not enough space to cache rdd_414_3 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:29 WARN  MemoryStore:66 - Not enough space to cache rdd_414_4 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:29 WARN  MemoryStore:66 - Not enough space to cache rdd_414_0 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:29 WARN  MemoryStore:66 - Not enough space to cache rdd_414_5 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:29 WARN  MemoryStore:66 - Not enough space to cache rdd_414_1 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:29 WARN  MemoryStore:66 - Not enough space to cache rdd_414_2 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:30 WARN  MemoryStore:66 - Not enough space to cache rdd_414_6 in memory! (computed 362.1 MB so far)\n",
      "2020-01-26 17:40:34 WARN  MemoryStore:66 - Not enough space to cache rdd_414_5 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:34 WARN  MemoryStore:66 - Not enough space to cache rdd_414_7 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:34 WARN  MemoryStore:66 - Not enough space to cache rdd_414_2 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:34 WARN  MemoryStore:66 - Not enough space to cache rdd_414_4 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:34 WARN  MemoryStore:66 - Not enough space to cache rdd_414_6 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:34 WARN  MemoryStore:66 - Not enough space to cache rdd_414_1 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:34 WARN  MemoryStore:66 - Not enough space to cache rdd_414_0 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:34 WARN  MemoryStore:66 - Not enough space to cache rdd_414_3 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:38 WARN  MemoryStore:66 - Not enough space to cache rdd_414_7 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:38 WARN  MemoryStore:66 - Not enough space to cache rdd_414_2 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:39 WARN  MemoryStore:66 - Not enough space to cache rdd_414_3 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:39 WARN  MemoryStore:66 - Not enough space to cache rdd_414_4 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:39 WARN  MemoryStore:66 - Not enough space to cache rdd_414_6 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:39 WARN  MemoryStore:66 - Not enough space to cache rdd_414_0 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:39 WARN  MemoryStore:66 - Not enough space to cache rdd_414_1 in memory! (computed 46.0 MB so far)\n",
      "2020-01-26 17:40:39 WARN  MemoryStore:66 - Not enough space to cache rdd_414_5 in memory! (computed 46.0 MB so far)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.PipelineModel = pipeline_e4bd24ccb25b\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = pipeline.fit(raw_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write.overwrite().save(\"./models/spark-ml-model-rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sameModel: org.apache.spark.ml.PipelineModel = pipeline_e4bd24ccb25b\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sameModel = PipelineModel.load(\"./models/spark-ml-model-rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|label|               tweet|               words|            features|indexedLabel|     indexedFeatures|       rawPrediction|         probability|prediction|predictedLabel|\n",
      "+-----+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "|    0|@switchfoot http:...|[@switchfoot, htt...|(1000,[7,14,21,54...|         0.0|(1000,[7,14,21,54...|[4.39665546729450...|[0.43966554672945...|       1.0|             1|\n",
      "|    0|is upset that he ...|[is, upset, that,...|(1000,[170,193,22...|         0.0|(1000,[170,193,22...|[5.24037086071899...|[0.52403708607189...|       0.0|             0|\n",
      "|    0|@Kenichan I dived...|[@kenichan, i, di...|(1000,[10,36,77,1...|         0.0|(1000,[10,36,77,1...|[5.89570496145148...|[0.58957049614514...|       0.0|             0|\n",
      "|    0|my whole body fee...|[my, whole, body,...|(1000,[82,191,296...|         0.0|(1000,[82,191,296...|[5.50444084723814...|[0.55044408472381...|       0.0|             0|\n",
      "|    0|@nationwideclass ...|[@nationwideclass...|(1000,[18,96,130,...|         0.0|(1000,[18,96,130,...|[5.19549953312632...|[0.51954995331263...|       0.0|             0|\n",
      "|    0|@Kwesidei not the...|[@kwesidei, not, ...|(1000,[18,223,710...|         0.0|(1000,[18,223,710...|[4.89510838998072...|[0.48951083899807...|       1.0|             1|\n",
      "|    0|         Need a hug |      [need, a, hug]|(1000,[48,170,537...|         0.0|(1000,[48,170,537...|[4.89510838998072...|[0.48951083899807...|       1.0|             1|\n",
      "|    0|@LOLTrish hey  lo...|[@loltrish, hey, ...|(1000,[139,157,17...|         0.0|(1000,[139,157,17...|[4.74406965363248...|[0.47440696536324...|       1.0|             1|\n",
      "|    0|@Tatiana_K nope t...|[@tatiana_k, nope...|(1000,[48,234,299...|         0.0|(1000,[48,234,299...|[4.89510838998072...|[0.48951083899807...|       1.0|             1|\n",
      "|    0|@twittera que me ...|[@twittera, que, ...|(1000,[161,324,47...|         0.0|(1000,[161,324,47...|[4.95703809211263...|[0.49570380921126...|       1.0|             1|\n",
      "|    0|spring break in p...|[spring, break, i...|(1000,[13,193,301...|         0.0|(1000,[13,193,301...|[4.89510838998072...|[0.48951083899807...|       1.0|             1|\n",
      "|    0|I just re-pierced...|[i, just, re-pier...|(1000,[307,329,47...|         0.0|(1000,[307,329,47...|[5.50444084723814...|[0.55044408472381...|       0.0|             0|\n",
      "|    0|@caregiving I cou...|[@caregiving, i, ...|(1000,[56,202,234...|         0.0|(1000,[56,202,234...|[5.60915213285671...|[0.56091521328567...|       0.0|             0|\n",
      "|    0|@octolinz16 It it...|[@octolinz16, it,...|(1000,[126,230,32...|         0.0|(1000,[126,230,32...|[4.24412635915465...|[0.42441263591546...|       1.0|             1|\n",
      "|    0|@smarrison i woul...|[@smarrison, i, w...|(1000,[18,83,170,...|         0.0|(1000,[18,83,170,...|[5.13578399398441...|[0.51357839939844...|       0.0|             0|\n",
      "|    0|@iamjazzyfizzle I...|[@iamjazzyfizzle,...|(1000,[7,71,202,2...|         0.0|(1000,[7,71,202,2...|[4.78199090202956...|[0.47819909020295...|       1.0|             1|\n",
      "|    0|Hollis' death sce...|[hollis', death, ...|(1000,[2,3,18,82,...|         0.0|(1000,[2,3,18,82,...|[5.00742407698274...|[0.50074240769827...|       0.0|             0|\n",
      "|    0|about to file taxes |[about, to, file,...|(1000,[108,388,48...|         0.0|(1000,[108,388,48...|[4.89510838998072...|[0.48951083899807...|       1.0|             1|\n",
      "|    0|@LettyA ahh ive a...|[@lettya, ahh, iv...|(1000,[13,107,201...|         0.0|(1000,[13,107,201...|[4.44034146539780...|[0.44403414653978...|       1.0|             1|\n",
      "|    0|@FakerPattyPattz ...|[@fakerpattypattz...|(1000,[53,102,154...|         0.0|(1000,[53,102,154...|[4.55948668791428...|[0.45594866879142...|       1.0|             1|\n",
      "+-----+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionsDF: org.apache.spark.sql.DataFrame = [label: int, tweet: string ... 8 more fields]\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionsDF = sameModel.transform(raw_sentiment)\n",
    "\n",
    "predictionsDF.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
