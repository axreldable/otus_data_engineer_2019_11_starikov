{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://mbp-aleksei:4041\n",
       "SparkContext available as 'sc' (version = 2.4.5, master = local[*], app id = local-1586357200484)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.5\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
       "dataSchema: org.apache.spark.sql.types.StructType = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath: String = ./data/training.1600000.processed.noemoticon.csv\n",
       "raw_sentiment: org.apache.spark.sql.DataFrame = [label: int, tweet: string]\n",
       "tweets: org.apache.spark.sql.DataFrame = [tweet: string]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "    \n",
    "val dataPath= \"./data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "val raw_sentiment = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\",\"tweet\")\n",
    "\n",
    "raw_sentiment.groupBy($\"label\").count.show\n",
    "val tweets = raw_sentiment.select(\"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "|tweet                                                                                                              |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!    |\n",
      "|@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                          |\n",
      "|my whole body feels itchy and like its on fire                                                                     |\n",
      "|@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.     |\n",
      "|@Kwesidei not the whole crew                                                                                       |\n",
      "|Need a hug                                                                                                         |\n",
      "|@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                |\n",
      "|@Tatiana_K nope they didn't have it                                                                                |\n",
      "|@twittera que me muera ?                                                                                           |\n",
      "+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
       "import org.apache.spark.ml.linalg.Vector\n",
       "import org.apache.spark.sql.Row\n",
       "tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_7a3e50a2a253\n",
       "hashingTF: org.apache.spark.ml.feature.HashingTF = hashingTF_832426f01cd1\n",
       "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_9cf4e7b48c69\n",
       "fullPipeline: org.apache.spark.ml.Pipeline = pipeline_14f5873fda49\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "val lr = new LogisticRegression()\n",
    "    .setMaxIter(10)\n",
    "    .setRegParam(0.001)\n",
    "\n",
    "val fullPipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preparePipeline: org.apache.spark.ml.Pipeline = pipeline_22cb45455aaa\n",
       "modelPipeline: org.apache.spark.ml.Pipeline = pipeline_75af386658f3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val preparePipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF))\n",
    "\n",
    "val modelPipeline = new Pipeline()\n",
    "  .setStages(Array(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullModel: org.apache.spark.ml.PipelineModel = pipeline_14f5873fda49\n",
       "prepareModel: org.apache.spark.ml.PipelineModel = pipeline_22cb45455aaa\n",
       "preparedDf: org.apache.spark.sql.DataFrame = [label: int, tweet: string ... 2 more fields]\n",
       "modelModel: org.apache.spark.ml.PipelineModel = pipeline_75af386658f3\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fullModel = fullPipeline.fit(raw_sentiment)\n",
    "val prepareModel = preparePipeline.fit(raw_sentiment)\n",
    "val preparedDf = prepareModel.transform(raw_sentiment)\n",
    "val modelModel = modelPipeline.fit(preparedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullModel.write.overwrite().save(\"./fullModel/spark-ml-model\")\n",
    "prepareModel.write.overwrite().save(\"./prepareModel/spark-ml-model\")\n",
    "modelModel.write.overwrite().save(\"./modelModel/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullModelFromFile: org.apache.spark.ml.PipelineModel = pipeline_14f5873fda49\n",
       "prepareModelFromFile: org.apache.spark.ml.PipelineModel = pipeline_22cb45455aaa\n",
       "modelModelFromFile: org.apache.spark.ml.PipelineModel = pipeline_75af386658f3\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fullModelFromFile = PipelineModel.load(\"./fullModel/spark-ml-model\")\n",
    "val prepareModelFromFile = PipelineModel.load(\"./prepareModel/spark-ml-model\")\n",
    "val modelModelFromFile = PipelineModel.load(\"./modelModel/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|@switchfoot http:...|[@switchfoot, htt...|(1000,[7,14,21,54...|[-0.9010125659402...|[0.28884245921785...|       1.0|\n",
      "|    0|is upset that he ...|[is, upset, that,...|(1000,[170,193,22...|[1.84195706807744...|[0.86318000204741...|       0.0|\n",
      "|    0|@Kenichan I dived...|[@kenichan, i, di...|(1000,[10,36,77,1...|[1.56488554961127...|[0.82705328017343...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fullModelResult: org.apache.spark.sql.DataFrame = [label: int, tweet: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fullModelResult = fullModelFromFile.transform(raw_sentiment)\n",
    "\n",
    "fullModelResult.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|               tweet|               words|            features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    0|@switchfoot http:...|[@switchfoot, htt...|(1000,[7,14,21,54...|\n",
      "|    0|is upset that he ...|[is, upset, that,...|(1000,[170,193,22...|\n",
      "|    0|@Kenichan I dived...|[@kenichan, i, di...|(1000,[10,36,77,1...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prepareModelResult: org.apache.spark.sql.DataFrame = [label: int, tweet: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prepareModelResult = prepareModelFromFile.transform(raw_sentiment)\n",
    "\n",
    "prepareModelResult.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|@switchfoot http:...|[@switchfoot, htt...|(1000,[7,14,21,54...|[-0.9010125659402...|[0.28884245921785...|       1.0|\n",
      "|    0|is upset that he ...|[is, upset, that,...|(1000,[170,193,22...|[1.84195706807744...|[0.86318000204741...|       0.0|\n",
      "|    0|@Kenichan I dived...|[@kenichan, i, di...|(1000,[10,36,77,1...|[1.56488554961127...|[0.82705328017343...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "modelModelResult: org.apache.spark.sql.DataFrame = [label: int, tweet: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val modelModelResult = modelModelFromFile.transform(prepareModelResult)\n",
    "\n",
    "modelModelResult.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "getProbability: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector) => prediction(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|  clean_probability|\n",
      "+-------------------+\n",
      "| 0.7111575407821429|\n",
      "|0.13681999795258062|\n",
      "| 0.1729467198265621|\n",
      "| 0.4445137910464958|\n",
      "|0.03783763627521715|\n",
      "|0.41759967706184536|\n",
      "| 0.4753971538982056|\n",
      "|  0.912918885817382|\n",
      "|0.30397625759950175|\n",
      "| 0.5326649357031025|\n",
      "| 0.4390689703426488|\n",
      "| 0.5978735997545636|\n",
      "| 0.3332295562520034|\n",
      "| 0.4913598594117323|\n",
      "|0.04828581755526847|\n",
      "|0.21764493477476207|\n",
      "|0.26225986886407654|\n",
      "| 0.5282380556537423|\n",
      "| 0.7151514980011853|\n",
      "| 0.7542266623347162|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelModelResult.select(getProbability($\"probability\").alias(\"clean_probability\")).show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
